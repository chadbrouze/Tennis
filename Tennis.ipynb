{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The learning algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This reinforcement learning task was solved using Deep Deterministic Policy Gradient, an algorithm created by OpenAI. DDPG is closely related to Q-learning but adapted for use in continuous spaces. The algorithm utilises innovations from Q-learning such as fixed target and experience replay. The algorithm falls under an umbrella called the Actor-Critic method and consists of 4 networks: actor, critic, target-actor and target-critic. \n",
    "\n",
    "The algorithm uses the current actor-network to choose an action a based on input state s, and the environment returns reward r and next_state s’. In the replay buffer, this is stored as an experience tuple, <s,a,r,s’>. The replay buffer is used to break correlations between consecutive experience tuples. The max size is 750000, and once it is full, the oldest experiences are discarded. Once BATCH_SIZE experiences are in the buffer, the agent begins learning.\n",
    "\n",
    "The current actor and critic networks are updated as follows:\n",
    "1) A minibatch of experience tuples is sampled from the replay buffer randomly. \n",
    "2) Action a’ is then chosen by the target-actor and evaluated by the target-critic. \n",
    "3) This value is then discounted by gamma, added to reward r to from y.\n",
    "4) The loss is then calculated by the MSE of y, and the expected value of action a calculated by the current critic.\n",
    "5) This loss is used to update the current critic through backpropagation.\n",
    "6) We then update the actor-network by taking the derivative of the critic network with respect to the policy parameters, using the mean of the gradients in the mini-batch.\n",
    "\n",
    "The target networks are just delayed copies of the actor and critic networks, which improves stability as the agent is chasing a much slower-moving target. Every episode, these target networks are updated by a small amount, tau, to match the current actor and critic closely. This project performs a hard update (current weights completely transferred to target weights) every HARD_FREQ, reducing training time without causing any stability issues.\n",
    "\n",
    "In this implementation, agents share their experience by soft copying eachothers local actor networks every 100 episodes. Each agent has its own replay buffer, and set of neural networks. Although, hyperparameters are the same for both. Each timestep, both agents undergo the same update process.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BUFFER_SIZE = int(0.75e6) #smaller than usual due to having 2    \n",
    "BATCH_SIZE = 256        # chosen to fit in GPU memory   \n",
    "GAMMA = 0.95           # discount factor   \n",
    "TAU = 0.5e-3              # low due to addition of hard updates   \n",
    "LR_ACTOR = 1e-4         # learning rate of the actor    \n",
    "LR_CRITIC = 1e-4        # learning rate of the critic   \n",
    "WEIGHT_DECAY = 0        # L2 weight decay   \n",
    "EPSILON_DEC =0.995   #noise reduction   \n",
    "TRAIN_FREQ=10     #how often train agent   \n",
    "HARD_FREQ=200    #how often to perform the hard update   \n",
    "TRAIN_N=5      #how many times train agent   \n",
    "sharing=0.1    #agents share their ideas.  \n",
    "  \n",
    "fc_1 = 350 #smaller to combat multi agent instability   \n",
    "fc_2 = 250 #decrease as action vector much smaller than state vector        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enviroment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mtensorflow 1.7.1 has requirement numpy>=1.13.3, but you'll have numpy 1.12.1 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mipython 6.5.0 has requirement prompt-toolkit<2.0.0,>=1.0.15, but you'll have prompt-toolkit 3.0.29 which is incompatible.\u001b[0m\r\n",
      "\u001b[31mjupyter-console 6.4.3 has requirement jupyter-client>=7.0.0, but you'll have jupyter-client 5.2.4 which is incompatible.\u001b[0m\r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "!pip -q install ./python\n",
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "\n",
    "env = UnityEnvironment(file_name=\"/data/Tennis_Linux_NoVis/Tennis\")\n",
    "\n",
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from Agent import Agent\n",
    "\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "agent0 = Agent(state_size=24, action_size= 2, random_seed=2)\n",
    "agent1 = Agent(state_size=24, action_size= 2, random_seed=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tScore: 0.00\tAverage Score over 100 episodes: -0.00\n",
      "Episode 200\tScore: 0.00\tAverage Score over 100 episodes: 0.00\n",
      "Episode 300\tScore: 0.00\tAverage Score over 100 episodes: 0.00\n",
      "Episode 400\tScore: 0.00\tAverage Score over 100 episodes: 0.00\n",
      "Episode 500\tScore: 0.00\tAverage Score over 100 episodes: 0.01\n",
      "Episode 600\tScore: 0.00\tAverage Score over 100 episodes: 0.03\n",
      "Episode 700\tScore: 0.00\tAverage Score over 100 episodes: 0.03\n",
      "Episode 800\tScore: 0.10\tAverage Score over 100 episodes: 0.05\n",
      "Episode 900\tScore: 0.10\tAverage Score over 100 episodes: 0.06\n",
      "Episode 1000\tScore: 0.10\tAverage Score over 100 episodes: 0.07\n",
      "Episode 1100\tScore: 0.10\tAverage Score over 100 episodes: 0.06\n",
      "Episode 1200\tScore: 0.09\tAverage Score over 100 episodes: 0.08\n",
      "Episode 1300\tScore: 0.10\tAverage Score over 100 episodes: 0.09\n",
      "Episode 1400\tScore: 0.20\tAverage Score over 100 episodes: 0.14\n",
      "Episode 1500\tScore: 0.20\tAverage Score over 100 episodes: 0.28\n",
      "Episode 1550\tScore: 1.10\tAverage Score over 100 episodes: 0.50\n",
      "\n",
      "Environment solved in 1450 episodes!\tEnded in episode: 1550\n"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=2500, max_t=1000, print_every=100, sharing=0.1):\n",
    "    scores_deque0 = deque(maxlen=print_every)\n",
    "    scores_deque1 = deque(maxlen=print_every)\n",
    "    scores0 = []\n",
    "    scores1 = []\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name]\n",
    "        state0 = env_info.vector_observations[0] \n",
    "        state1 = env_info.vector_observations[1] \n",
    "        agent0.reset()\n",
    "        agent1.reset()\n",
    "        score0 = 0\n",
    "        score1 = 0\n",
    "        for t in range(max_t):\n",
    "            action0 = agent0.act(state0)\n",
    "            action1 = agent1.act(state1)\n",
    "            env_info = env.step(np.array([action0,action1]))[brain_name]\n",
    "            next_state0 = env_info.vector_observations[0]  \n",
    "            next_state1 = env_info.vector_observations[1] \n",
    "            reward0 = env_info.rewards[0]     \n",
    "            reward1 = env_info.rewards[1] \n",
    "            done0 = env_info.local_done[0]   \n",
    "            done1 = env_info.local_done[1]\n",
    "            agent0.step(state0, action0, reward0, next_state0, done0)\n",
    "            agent1.step(state1, action1, reward1, next_state1, done1)\n",
    "            state0 = next_state0\n",
    "            state1 = next_state1\n",
    "            score0 += reward0\n",
    "            score1 += reward1\n",
    "             \n",
    "            if done0 or done1:\n",
    "                break \n",
    "        scores_deque0.append(score0)\n",
    "        scores_deque1.append(score1)\n",
    "        scores0.append(score0)\n",
    "        scores1.append(score1)\n",
    "        if i_episode % print_every == 0:\n",
    "            print('\\rEpisode {}\\tScore: {:.2f}\\tAverage Score over 100 episodes: {:.2f}'.format(i_episode, max(score0,score1), max(np.mean(scores_deque0),np.mean(scores_deque1)), end=\"\\n\"))\n",
    "            \n",
    "            #agents share their experience\n",
    "            for actor0_param, actor1_param in zip(agent0.actor_local.parameters(), \n",
    "agent1.actor_local.parameters()):\n",
    "                actor0_param.data.copy_(sharing*actor1_param.data + \n",
    "(1.0-sharing)*actor0_param.data)\n",
    "                actor1_param.data.copy_(sharing*actor0_param.data + \n",
    "(1.0-sharing)*actor1_param.data)\n",
    "                  \n",
    "        if max(np.mean(scores_deque0), np.mean(scores_deque1)) >= 0.5:\n",
    "            print('\\rEpisode {}\\tScore: {:.2f}\\tAverage Score over 100 episodes: {:.2f}'.format(i_episode, max(score0,score1), max(np.mean(scores_deque0),np.mean(scores_deque1)), end=\"\\n\"))\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tEnded in episode: {:d}'.format(i_episode-100,i_episode ))\n",
    "            torch.save(agent0.actor_local.state_dict(), 'checkpoint_actor.pth')\n",
    "            torch.save(agent0.critic_local.state_dict(), 'checkpoint_critic.pth')\n",
    "            break    \n",
    "            \n",
    "    return scores0\n",
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enviroment was solved in 1000 episodes. Below is a plot of scores per episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f74185ba828>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(scores)\n",
    "plt.xlabel('episode')\n",
    "plt.ylabel('score')\n",
    "plt.title('Plot of score over episodes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future Imporvement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparamters could use a lot more tuning. In addition it may be worthwile adding memory collaboration (agents share experiences from their replay buffers). In addition, it is likely that placing prior- ity on important/rare experience tuple will lead to faster convergence. Also lot more investigation can be done on the exploration vs exploitation front, as adding noise is far more abstract than the epsilon greedy policy used in regular Q-learning. In addition, the Ornstein-Uhlenbeck process may be an overly complex way to add noise, and simpler methods like normally distributed may also work."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
